{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1\n",
    "#loading data\n",
    "dataTrain = pd.read_csv('./features.csv', index_col='match_id')\n",
    "dataTest = pd.read_csv('./features_test.csv', index_col='match_id')\n",
    "\n",
    "#4\n",
    "#target variable\n",
    "yTrain = dataTrain['radiant_win']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#deleting features conected to end of match\n",
    "difference = set(dataTrain.columns.values) - set(dataTest.columns.values)\n",
    "dataTrain.drop(difference, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total size =  97230\n",
      "\n",
      " Column |  Number of missing values \n",
      "\n",
      "first_blood_time  |  19553\n",
      "first_blood_team  |  19553\n",
      "first_blood_player1  |  19553\n",
      "first_blood_player2  |  43987\n",
      "radiant_bottle_time  |  15691\n",
      "radiant_courier_time  |  692\n",
      "radiant_flying_courier_time  |  27479\n",
      "radiant_first_ward_time  |  1836\n",
      "dire_bottle_time  |  16143\n",
      "dire_courier_time  |  676\n",
      "dire_flying_courier_time  |  26098\n",
      "dire_first_ward_time  |  1826\n"
     ]
    }
   ],
   "source": [
    "#2\n",
    "#checking for missing variables\n",
    "totalSize = len(dataTrain)\n",
    "print('Total size = ', totalSize)\n",
    "\n",
    "print('\\n Column |  Number of missing values \\n')\n",
    "\n",
    "for col in dataTrain:\n",
    "    colSize = dataTrain[col].count()\n",
    "    if colSize != totalSize:\n",
    "        print(col, ' | ' , totalSize - colSize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3\n",
    "#replacing missing variables with zeroes\n",
    "dataTrain.fillna(0, method=None, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 1: Gradient Boosting (\"naive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed: 0:00:44.910946\n",
      "Number of trees(n_estimators): 10 Quality assessment:  66.3867612978\n",
      "Time elapsed: 0:01:15.082123\n",
      "Number of trees(n_estimators): 20 Quality assessment:  68.204986854\n",
      "Time elapsed: 0:01:44.978186\n",
      "Number of trees(n_estimators): 30 Quality assessment:  69.017613343\n",
      "Time elapsed: 0:02:18.634746\n",
      "Number of trees(n_estimators): 40 Quality assessment:  69.46467938\n",
      "Time elapsed: 0:02:52.281933\n",
      "Number of trees(n_estimators): 50 Quality assessment:  69.7650533861\n",
      "Time elapsed: 0:03:25.689071\n",
      "Number of trees(n_estimators): 60 Quality assessment:  70.0232288054\n",
      "Time elapsed: 0:04:02.081581\n",
      "Number of trees(n_estimators): 70 Quality assessment:  70.2432088261\n"
     ]
    }
   ],
   "source": [
    "#5\n",
    "#GB trees\n",
    "kf = KFold(n_splits=5,shuffle=True)\n",
    "\n",
    "nsTrees = [10, 20, 30, 40, 50, 60, 70]\n",
    "qualities = []\n",
    "\n",
    "for nTrees in nsTrees:\n",
    "    clf = GradientBoostingClassifier(n_estimators=nTrees, random_state=42)\n",
    "    \n",
    "    start_time = datetime.datetime.now()\n",
    "    scores = cross_val_score(clf, dataTrain, yTrain, scoring='roc_auc', cv=kf)\n",
    "    print('Time elapsed:', datetime.datetime.now() - start_time)\n",
    "    \n",
    "    quality = scores.mean() * 100\n",
    "    qualities.append(quality)\n",
    "    \n",
    "    print(\"Number of trees(n_estimators):\", nTrees, 'Quality assessment: ', quality)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimant 2: Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without scaling:\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:   36.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed: 0:00:03.129821 Quality assessment: 51.3444570606\n",
      "\n",
      "With scaling:\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:  3.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed: 0:00:18.729711 Quality assessment: 71.6366215074\n"
     ]
    }
   ],
   "source": [
    "#1\n",
    "#LR (naive)\n",
    "grid = {'C': np.logspace(-3, -1, 10)}\n",
    "\n",
    "def scoreLR(data):\n",
    "    #looking for best C\n",
    "    clf_grid = GridSearchCV(LogisticRegression(random_state=42,n_jobs=-1), grid, cv=kf, n_jobs=1, verbose=1, scoring='roc_auc')\n",
    "    clf_grid.fit(data, yTrain)\n",
    "    \n",
    "    #creating LR with best C\n",
    "    lr = LogisticRegression(n_jobs=-1,random_state=42,**clf_grid.best_params_)\n",
    "    lr.fit(data, yTrain)\n",
    "    \n",
    "    #Cross Validation\n",
    "    start_time = datetime.datetime.now()\n",
    "    scores = cross_val_score(lr, data, yTrain, scoring='roc_auc', cv=kf)\n",
    "    print('Time elapsed:', datetime.datetime.now() - start_time, end=' ')\n",
    "    quality = scores.mean()*100\n",
    "    print(\"Quality assessment:\", quality)\n",
    "    \n",
    "print(\"Without scaling:\")\n",
    "scoreLR(dataTrain)\n",
    "\n",
    "print(\"\\nWith scaling:\")\n",
    "scoreLR(StandardScaler().fit_transform(dataTrain))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2\n",
    "#Removing categoracal features\n",
    "colsToDrop = ['r%s_hero' % i for i in range(1, 6)] + ['d%s_hero' % i for i in range(1, 6)]\n",
    "colsToDrop.append('lobby_type')\n",
    "\n",
    "dataTrainNorm_NoCateg = pd.DataFrame(data=StandardScaler().fit_transform(dataTrain.drop(colsToDrop, axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:  3.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed: 0:00:22.585292 Quality assessment: 71.6590480143\n"
     ]
    }
   ],
   "source": [
    "scoreLR(dataTrainNorm_NoCateg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108\n"
     ]
    }
   ],
   "source": [
    "#3\n",
    "#number of types of heroes\n",
    "colsToDrop.remove('lobby_type')\n",
    "N = len(set(dataTrain[colsToDrop].values.flatten()))\n",
    "print(N)\n",
    "m = max(set(dataTrain[colsToDrop].values.flatten()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Elise\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate_ix\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "#4\n",
    "#Bag of words to code info obout type of hero\n",
    "X_pick = np.zeros((dataTrain.shape[0], m))\n",
    "\n",
    "for i, match_id in enumerate(dataTrain.index):\n",
    "    for p in range(5):\n",
    "        X_pick[i, dataTrain.ix[match_id, 'r%d_hero' % (p+1)]-1] = 1\n",
    "        X_pick[i, dataTrain.ix[match_id, 'd%d_hero' % (p+1)]-1] = -1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:  5.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed: 0:00:42.937456 Quality assessment: 75.1834640228\n"
     ]
    }
   ],
   "source": [
    "#5\n",
    "#LR (after BoW)\n",
    "\n",
    "dataTrainBW = dataTrainNorm_NoCateg.join(pd.DataFrame(X_pick),rsuffix='_',how='inner')\n",
    "scoreLR(dataTrainBW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:  5.5min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.059948425031894091, class_weight=None, dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='ovr', n_jobs=-1, penalty='l2', random_state=42,\n",
       "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#6\n",
    "#Predictions for test data\n",
    "\n",
    "#looking for best C\n",
    "clf_grid = GridSearchCV(LogisticRegression(random_state=42,n_jobs=-1), grid, cv=kf, n_jobs=1, verbose=1, scoring='roc_auc')\n",
    "clf_grid.fit(dataTrainBW, yTrain)\n",
    "    \n",
    "#creating LR with best C\n",
    "lr = LogisticRegression(n_jobs=-1,random_state=42,**clf_grid.best_params_)\n",
    "lr.fit(dataTrainBW, yTrain)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max: 0.996420513116 Min: 0.00357948688392\n"
     ]
    }
   ],
   "source": [
    "#Preparing testing data\n",
    "dataTest.fillna(0, method=None, axis=1, inplace=True)\n",
    "\n",
    "#colsToDrop.append('lobby_type')\n",
    "\n",
    "dataTestDrop = pd.DataFrame(data=StandardScaler().fit_transform(dataTest.drop(colsToDrop, axis=1)))\n",
    "\n",
    "X_pick = np.zeros((dataTest.shape[0], m))\n",
    "\n",
    "for i, match_id in enumerate(dataTest.index):\n",
    "    for p in range(5):\n",
    "        X_pick[i, dataTest.ix[match_id, 'r%d_hero' % (p+1)]-1] = 1\n",
    "        X_pick[i, dataTest.ix[match_id, 'd%d_hero' % (p+1)]-1] = -1\n",
    "\n",
    "dataTestBW = dataTestDrop.join(pd.DataFrame(X_pick),rsuffix='_',how='inner')\n",
    "\n",
    "#testing\n",
    "yPred = lr.predict_proba(dataTestBW)\n",
    "\n",
    "print(\"Max:\" , yPred.max(), \"Min:\", yPred.min())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
